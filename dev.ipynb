{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from markitdown import MarkItDown\n",
    "import openai\n",
    "import bs4\n",
    "import re\n",
    "from pydantic import BaseModel\n",
    "from datetime import date, datetime\n",
    "from typing import Optional\n",
    "from bs4 import BeautifulSoup\n",
    "import dotenv\n",
    "from utils import convert_pdf\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import colorlog\n",
    "from humanize import filesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = colorlog.getLogger(__name__)\n",
    "handler = colorlog.StreamHandler()\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.DEBUG)  # Set the desired logging level\n",
    "\n",
    "# Add file log output to ./logs/\n",
    "file_handler = logging.FileHandler(\"logs/scrape.log\", mode=\"a\")\n",
    "\n",
    "formatter = colorlog.ColoredFormatter(\n",
    "    \"%(log_color)s%(asctime)s %(levelname)s: %(message)s\",\n",
    "    log_colors={\n",
    "        \"DEBUG\": \"cyan\",\n",
    "        \"INFO\": \"green\",\n",
    "        \"WARNING\": \"yellow\",\n",
    "        \"ERROR\": \"red\",\n",
    "        \"CRITICAL\": \"red,bg_white\",\n",
    "    },\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "ENV = dotenv.dotenv_values()\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    api_key=ENV[\"AZURE_OPENAI_KEY\"],\n",
    "    api_version=ENV[\"OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=ENV[\"AZURE_OPENAI_ENDPOINT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(text):\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"\\s+\", \"-\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting all bills  from https://www.barbadosparliament.com/bills/ asynch\n",
    "# Save raw HTML to ./data/legislature/bills/html\n",
    "# Save parsed data to ./data/legislature/bills/json\n",
    "\n",
    "\n",
    "base_bill_url = \"https://www.barbadosparliament.com/bills/\"\n",
    "\n",
    "\n",
    "class Bill(BaseModel):\n",
    "    bill_id: int\n",
    "    slug: str\n",
    "    title: str\n",
    "    pdf_url: Optional[str]\n",
    "    current_stage: Optional[str]\n",
    "    chamber: Optional[str]\n",
    "    notice_date: Optional[date]\n",
    "    first_reading: Optional[date]\n",
    "    gazette_date: Optional[date]\n",
    "    markdown: Optional[str]\n",
    "\n",
    "\n",
    "def extract_bill_metadata(html: str, bill_id: int) -> Bill:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract the bill title from the <h2> tag. The title is assumed to be the first text node.\n",
    "    h2 = soup.find(\"h2\")\n",
    "    title = h2.find(string=True, recursive=False).strip() if h2 else \"\"\n",
    "\n",
    "    # Extract PDF URL from the <a> tag inside the <h2>\n",
    "    pdf_anchor = h2.find(\"a\") if h2 else None\n",
    "    pdf_url = pdf_anchor.get(\"href\") if pdf_anchor else None\n",
    "    pdf_url = \"https://www.barbadosparliament.com/\" + pdf_url if pdf_url else None\n",
    "\n",
    "    # Initialize metadata values\n",
    "    current_stage = None\n",
    "    notice_date = None\n",
    "    first_reading = None\n",
    "    gazette_date = None\n",
    "    chamber = None\n",
    "\n",
    "    table = soup.find(\"table\")\n",
    "    if table:\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            th = tr.find(\"th\")\n",
    "            tds = tr.find_all(\"td\")\n",
    "            if th:\n",
    "                key = th.get_text(strip=True)\n",
    "                if key == \"Current Stage\" and tds:\n",
    "                    current_stage = tds[0].get_text(strip=True)\n",
    "                elif key.startswith(\"Notice Date\") and tds:\n",
    "                    date_str = tds[0].get_text(strip=True)\n",
    "                    try:\n",
    "                        notice_date = datetime.strptime(date_str, \"%d/%m/%Y\").date()\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                elif key.startswith(\"First reading\") and tds:\n",
    "                    date_str = tds[0].get_text(strip=True)\n",
    "                    try:\n",
    "                        first_reading = datetime.strptime(date_str, \"%d/%m/%Y\").date()\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                elif key.startswith(\"First appeared in the Official Gazette\") and tds:\n",
    "                    date_str = tds[0].get_text(strip=True)\n",
    "                    try:\n",
    "                        gazette_date = datetime.strptime(date_str, \"%d/%m/%Y\").date()\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            else:\n",
    "                # This row may contain the chamber information.\n",
    "                td = tr.find(\"td\", attrs={\"colspan\": \"2\"})\n",
    "                if td:\n",
    "                    chamber = td.get_text(strip=True)\n",
    "\n",
    "    return Bill(\n",
    "        bill_id=bill_id,\n",
    "        title=title,\n",
    "        slug=slugify(title),\n",
    "        pdf_url=pdf_url,\n",
    "        current_stage=current_stage,\n",
    "        chamber=chamber,\n",
    "        notice_date=notice_date,\n",
    "        first_reading=first_reading,\n",
    "        gazette_date=gazette_date,\n",
    "        markdown=None,\n",
    "    )\n",
    "\n",
    "\n",
    "class MissingBillIDException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def scrape_bill(bill_id: int):\n",
    "    \"\"\"\n",
    "    Scrapes a bill from the Barbados Parliament website.\n",
    "\n",
    "    Args:\n",
    "        bill_id (id): The ID of the bill to scrape.\n",
    "    \"\"\"\n",
    "\n",
    "    bill_url = f\"https://www.barbadosparliament.com/bills/details/{bill_id}\"\n",
    "\n",
    "    logger.debug(\"üåê Fetching %s\", bill_url)\n",
    "    bill_webpage = requests.get(bill_url)\n",
    "    bill_webpage.raise_for_status()\n",
    "\n",
    "    # Check if the page is an error page\n",
    "    if \"A PHP Error was encountered\" in bill_webpage.text:\n",
    "        logger.warning(\"‚ùå Bill %s not found\", bill_id)\n",
    "\n",
    "        # Add a dud JSON file to stop us re-scraping this bill\n",
    "        json_path = f\"./data/legislature/bills/json/{bill_id}_not_found.json\"\n",
    "        with open(json_path, \"w\") as f:\n",
    "            f.write(\"{}\")\n",
    "\n",
    "        raise MissingBillIDException(f\"Bill {bill_id} not found\")\n",
    "\n",
    "    # Parse the bill metadata\n",
    "    logger.debug(\"üîé Extracting bill metadata for bill_id %s\", str(bill_id))\n",
    "    bill = extract_bill_metadata(html=bill_webpage.text, bill_id=bill_id)\n",
    "\n",
    "    # Save raw HTML to ./data/legislature/bills/html\n",
    "    html_path = f\"./data/legislature/bills/html/{bill.bill_id}_{bill.slug}.html\"\n",
    "    with open(html_path, \"w\") as f:\n",
    "        f.write(bill_webpage.text)\n",
    "        logger.debug(\"‚úÖ Saved %s\", html_path)\n",
    "\n",
    "    # Save pdf to ./data/legislature/bills/pdf\n",
    "    logger.debug(\"üíæ Downloading PDF: %s\", bill.pdf_url)\n",
    "    pdf_resp = requests.get(url=bill.pdf_url, timeout=60)\n",
    "    pdf_resp.raise_for_status()\n",
    "\n",
    "    pdf_path = f\"./data/legislature/bills/pdf/{bill.bill_id}_{bill.slug}.pdf\"\n",
    "    with open(pdf_path, \"wb\") as f:\n",
    "        f.write(pdf_resp.content)\n",
    "        pdf_size_str = filesize.naturalsize(os.path.getsize(pdf_path))\n",
    "        logger.debug(\"‚úÖ Saved (%s) %s\", pdf_size_str, pdf_path)\n",
    "\n",
    "    # Save markdown to ./data/legislature/bills/md\n",
    "\n",
    "    logger.debug(\"üìñ Converting %s to Markdown\", pdf_path)\n",
    "    bill.markdown = convert_pdf(file_path=pdf_path)\n",
    "    markdown_path = f\"./data/legislature/bills/md/{bill.bill_id}_{bill.slug}.md\"\n",
    "    with open(markdown_path, \"w\") as f:\n",
    "        f.write(bill.markdown)\n",
    "        logger.debug(\"‚úÖ Saved %s\", markdown_path)\n",
    "\n",
    "    json_path = f\"./data/legislature/bills/json/{bill.bill_id}_{bill.slug}.json\"\n",
    "    # Save parsed data to ./data/legislature/bills/json\n",
    "    with open(json_path, \"w\") as f:\n",
    "        f.write(bill.model_dump_json(indent=2))\n",
    "\n",
    "    return bill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_bill_ids = [\n",
    "    int(x.split(\"_\")[0]) for x in os.listdir(\"./data/legislature/bills/json/\")\n",
    "]\n",
    "\n",
    "target_bill_id_min = 21\n",
    "target_bill_id_max = 824\n",
    "target_bill_ids = set(range(target_bill_id_min, target_bill_id_max + 1))\n",
    "target_bill_ids = target_bill_ids - set(completed_bill_ids)\n",
    "\n",
    "logger.info(\"üìú Scraping %s target bills\", len(target_bill_ids))\n",
    "\n",
    "for bill_id in tqdm(target_bill_ids, unit=\"bill\"):\n",
    "    # check if the bill_id has been scraped in the json data dir\n",
    "    try:\n",
    "        bill = scrape_bill(bill_id=bill_id)\n",
    "        logger.info(\"üìú Scraped bill: %s\", bill.title)\n",
    "    except MissingBillIDException as err:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
